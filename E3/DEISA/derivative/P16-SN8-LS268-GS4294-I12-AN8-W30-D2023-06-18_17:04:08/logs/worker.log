distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:34100'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:40595'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:34610'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:34953'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:45451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:37210'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:33341'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:33504'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:41942'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:34280'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:43479'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:43644'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:35830'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:40794'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:38273'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:39158'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:46720'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:38324'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:37535'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:35616'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:37048'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:39036'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:37536'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:40332'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:44523'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:46129'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:40563'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:41577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:33254'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:39081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:37037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:46365'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:34010'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:39245'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:42894'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:41494'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:33042'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:44856'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:38097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:40315'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:36603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:39521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:42877'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:42624'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33237'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33617'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:45297'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:41573'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:37251'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:45234'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:46570'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:40986'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:40464'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:41426'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:41202'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:41781'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:36093'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:37739'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:35893'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:46874'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:32983'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:38502'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:38506'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:37552'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:45080'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:41149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:35703'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:36571'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:43719'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:33671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:34005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:43520'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:35022'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:34296'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:39759'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:33607'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:34766'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:41104'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:41534'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:45520'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33302'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:44188'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:36435'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33559'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:44329'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:38687'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:43804'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:36743'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:41544'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38446'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:46065'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:44095'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:40016'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:33653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41514'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:40527'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:35655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:37586'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38882'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41664'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:46282'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41701'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:36676'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:42183'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:36121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38180'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:45467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:40632'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41279'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:42805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:44049'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:39879'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:34358'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41774'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:46239'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38949'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:32896'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:39074'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:46033'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:41861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:36756'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:43298'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:37950'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:34612'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:44485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:35453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:39119'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:43469'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:38328'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:38561'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:46772'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:44757'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:45037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:36710'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:43328'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:42349'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:38192'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:38800'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:39114'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:45291'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:45680'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:34189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:35348'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:33085'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:37768'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:37219'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:40169'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:37032'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:40624'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:45471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:37967'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:46330'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:41521'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:42358'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:34456'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:34100'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:36000'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:33024'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:39588'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:33992'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:39541'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:40611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:34858'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:33041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:36848'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:45958'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:41846'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:45891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:41604'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:39747'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:41222'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:33337'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:44650'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:35415'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:44103'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:42526'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:34007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:39307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:34393'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:40376'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:34255'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36826'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:37880'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:42915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36552'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36786'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:33030'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:37959'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:42994'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36816'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:35844'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:43581'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:40836'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:39270'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:44880'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:34062'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:45253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:46579'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36192'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:43257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:34935'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:35938'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:42161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:40210'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:38427'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:42244'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36684'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:33314'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:35760'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:43913'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:44826'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:46170'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:34009'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:42863'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:41802'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:33519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:36062'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:38675'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:32873'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:33127'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:41317'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:38886'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:34345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:46066'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:34986'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:39564'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:42792'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:45611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:40526'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:40575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:36525'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:36575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:33933'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:43699'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:45206'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:34120'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:43010'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:39326'
Exception in thread Profile:
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 115, in process
    d = state["children"][ident]
KeyError: '_generators;/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-bokeh-2.4.3-ymv7xmpcwmkqptf5n2cxjjfpcbesgkp4/lib/python3.10/site-packages/bokeh/core/has_props.py;120'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 274, in _watch
    process(frame, None, recent, omit=omit)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 119, in process
    "description": info_frame(frame),
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 72, in info_frame
    line = linecache.getline(co.co_filename, frame.f_lineno, frame.f_globals).lstrip()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/linecache.py", line 31, in getline
    if 1 <= lineno <= len(lines):
TypeError: '<=' not supported between instances of 'int' and 'NoneType'
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:41971
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:41971
distributed.worker - INFO -          dashboard at:           10.7.0.133:39300
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0981k1ed
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:37938
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:37938
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.133:33776
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:35628
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8i79g8un
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:35628
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:43996
distributed.worker - INFO -          dashboard at:           10.7.0.133:34748
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:43996
distributed.worker - INFO -          dashboard at:           10.7.0.133:46665
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jgkrs53r
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:43953
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:44563
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_c0toqro
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:43953
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:42380
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:42380
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:44563
distributed.worker - INFO -          dashboard at:           10.7.0.133:40417
distributed.worker - INFO -          dashboard at:           10.7.0.133:46583
distributed.worker - INFO -          dashboard at:           10.7.0.133:36798
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5qlcs3s0
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:41177
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:41196
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:42046
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:37662
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0ipeudic
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fn3t9jqa
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:34926
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:41177
distributed.worker - INFO -          dashboard at:           10.7.0.133:37784
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:40956
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:37662
distributed.worker - INFO -          dashboard at:           10.7.0.133:45728
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:34926
distributed.worker - INFO -          dashboard at:           10.7.0.133:37825
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:40956
distributed.worker - INFO -          dashboard at:           10.7.0.133:44322
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:43504
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:42958
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:41196
distributed.worker - INFO -          dashboard at:           10.7.0.133:40603
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:42958
distributed.worker - INFO -          dashboard at:           10.7.0.136:35007
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:42046
distributed.worker - INFO -          dashboard at:           10.7.0.133:36573
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-eqscrc_l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:43504
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bi36br_l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-v50hi0jd
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qtficlaj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:40208
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-k4qmsi_n
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.133:38991
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:40208
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tmz7sjng
distributed.worker - INFO -          dashboard at:           10.7.0.136:34938
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:42990
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:42990
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sy7sei2k
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:42647
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.133:35542
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-moxt777t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:42647
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h0rrx47h
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:42510
distributed.worker - INFO -          dashboard at:           10.7.0.133:33166
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:42510
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:38216
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7abk2qkx
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:35865
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.136:39595
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:38216
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l3649ceu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:43635
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.136:33434
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:43635
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:35865
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          dashboard at:           10.7.0.136:37331
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:42393
distributed.worker - INFO -          dashboard at:           10.7.0.136:44838
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-e1_oguo5
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:42393
distributed.worker - INFO -          dashboard at:           10.7.0.136:43786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-480i_fky
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:46099
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:35292
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:35292
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p39y016v
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:46099
distributed.worker - INFO -          dashboard at:           10.7.0.136:43696
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0grqobra
distributed.worker - INFO -          dashboard at:           10.7.0.136:38786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:36702
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:36702
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.136:42329
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3ondvqrb
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qzb1y4we
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gesqv91u
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-831ddl74
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:39163
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:39163
distributed.worker - INFO -          dashboard at:           10.7.0.136:34822
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-70qe5aex
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:35109
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:35109
distributed.worker - INFO -          dashboard at:           10.7.0.136:38527
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tlae_5b8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:46444
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:46444
distributed.worker - INFO -          dashboard at:           10.7.0.136:43685
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pdqm28_l
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:33503
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:33503
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:40489
distributed.worker - INFO -          dashboard at:           10.7.0.136:42722
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:40489
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.136:35885
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-yk76xkyp
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wl7vwylh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:35832
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:35832
distributed.worker - INFO -          dashboard at:           10.7.0.136:36957
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fetvoo93
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:38643
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:38643
distributed.worker - INFO -          dashboard at:           10.7.0.136:33811
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kg36_jhn
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:38620
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:38620
distributed.worker - INFO -          dashboard at:           10.7.0.136:32989
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pxnfmixd
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:43019
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:43019
distributed.worker - INFO -          dashboard at:           10.7.0.136:46231
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-g4aa4tj0
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:39571
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:39571
distributed.worker - INFO -          dashboard at:           10.7.0.136:34726
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-noatp4i9
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:45837
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:45837
distributed.worker - INFO -          dashboard at:           10.7.0.133:37753
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6bcro6dq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:34870
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:34870
distributed.worker - INFO -          dashboard at:           10.7.0.138:46339
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:36599
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:35397
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:36599
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:35397
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          dashboard at:           10.7.0.133:44288
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:43924
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.138:39690
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nb1qbllc
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:43924
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-68b5z5or
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.138:37920
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:39063
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:39063
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:40507
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4z50qwy6
distributed.worker - INFO -          dashboard at:           10.7.0.138:39306
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8g35_r5t
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:40507
distributed.worker - INFO -          dashboard at:           10.7.0.138:43354
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-iochxaxd
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:38957
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:38768
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:38957
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b8wqx6mu
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:40120
distributed.worker - INFO -          dashboard at:           10.7.0.138:35428
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:38768
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:44862
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:40120
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.138:41099
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          dashboard at:           10.7.0.138:45770
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:44862
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4c_bhwfh
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:41484
distributed.worker - INFO -          dashboard at:           10.7.0.138:35933
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:41484
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.138:39703
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kag2uay7
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:41227
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0amtnzpy
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:34977
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:34977
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:41227
distributed.worker - INFO -          dashboard at:           10.7.0.138:45344
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-g4segqk1
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3kzqtxuc
distributed.worker - INFO -          dashboard at:           10.7.0.138:38765
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-co0egs4v
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9166x05s
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:33582
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:37750
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:33582
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:37750
distributed.worker - INFO -          dashboard at:           10.7.0.138:46196
distributed.worker - INFO -          dashboard at:           10.7.0.138:38270
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:42249
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:42249
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          dashboard at:           10.7.0.138:33715
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_nsgrkyq
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-us0iq8h7
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-x3w_y6rf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:35732
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:35732
distributed.worker - INFO -          dashboard at:           10.7.0.138:39188
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3mb45fde
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:36528
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:36528
distributed.worker - INFO -          dashboard at:           10.7.0.133:37690
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sieu6n4h
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:33143
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:33143
distributed.worker - INFO -          dashboard at:           10.7.0.133:44150
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zz9cnvhw
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:34818
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:34818
distributed.worker - INFO -          dashboard at:           10.7.0.138:45675
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xwd7gpcb
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:41257
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:41257
distributed.worker - INFO -          dashboard at:           10.7.0.136:38155
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qi95avuc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:36602
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:36602
distributed.worker - INFO -          dashboard at:           10.7.0.138:43073
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fp3ibahq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:41171
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:41171
distributed.worker - INFO -          dashboard at:           10.7.0.138:46324
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4d8z4dng
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:35498
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:35498
distributed.worker - INFO -          dashboard at:           10.7.0.133:45536
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h2k2v4cz
distributed.worker - INFO - -------------------------------------------------
Exception in thread Profile:
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:33147
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:33147
distributed.worker - INFO -          dashboard at:           10.7.0.136:39770
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zn1m1zs7
distributed.worker - INFO - -------------------------------------------------
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 115, in process
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
    d = state["children"][ident]
KeyError: '_generators;/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-bokeh-2.4.3-ymv7xmpcwmkqptf5n2cxjjfpcbesgkp4/lib/python3.10/site-packages/bokeh/core/has_props.py;120'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
distributed.core - INFO - Starting established connection
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/threading.py", line 953, in run
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
    self._target(*self._args, **self._kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 274, in _watch
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:34719
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:34719
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
    process(frame, None, recent, omit=omit)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 119, in process
distributed.worker - INFO -          dashboard at:           10.7.0.138:44363
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-j7cs5fpc
distributed.worker - INFO - -------------------------------------------------
    "description": info_frame(frame),
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 72, in info_frame
    line = linecache.getline(co.co_filename, frame.f_lineno, frame.f_globals).lstrip()
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:43812
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:43812
distributed.worker - INFO -          dashboard at:           10.7.0.138:45358
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pym3c_4l
distributed.worker - INFO - -------------------------------------------------
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/linecache.py", line 31, in getline
    if 1 <= lineno <= len(lines):
TypeError: '<=' not supported between instances of 'int' and 'NoneType'
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:37411
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:37411
distributed.worker - INFO -          dashboard at:           10.7.0.133:46351
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1lqlevah
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:37422
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:37422
distributed.worker - INFO -          dashboard at:           10.7.0.138:34960
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zmhfj0pw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Exception in thread Profile:
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 115, in process
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:45345
    d = state["children"][ident]
KeyError: '_generators;/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-bokeh-2.4.3-ymv7xmpcwmkqptf5n2cxjjfpcbesgkp4/lib/python3.10/site-packages/bokeh/core/has_props.py;120'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:45345
distributed.worker - INFO -          dashboard at:           10.7.0.136:40572
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-yar9gm3r
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:33443
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:33443
distributed.worker - INFO -          dashboard at:           10.7.0.133:35671
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mkjot4iw
    self.run()
distributed.worker - INFO - -------------------------------------------------
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/threading.py", line 953, in run
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
    self._target(*self._args, **self._kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 274, in _watch
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
    process(frame, None, recent, omit=omit)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 119, in process
distributed.core - INFO - Starting established connection
    "description": info_frame(frame),
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 72, in info_frame
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
    line = linecache.getline(co.co_filename, frame.f_lineno, frame.f_globals).lstrip()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/linecache.py", line 31, in getline
distributed.core - INFO - Starting established connection
    if 1 <= lineno <= len(lines):
TypeError: '<=' not supported between instances of 'int' and 'NoneType'
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:34205
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:34205
distributed.worker - INFO -          dashboard at:           10.7.0.133:34715
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ux29kr0e
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:42696
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:42696
distributed.worker - INFO -          dashboard at:           10.7.0.138:41780
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mq9s0i67
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:38888
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:38888
distributed.worker - INFO -          dashboard at:           10.7.0.133:41535
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-39xzi0tz
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:34697
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:34697
distributed.worker - INFO -          dashboard at:           10.7.0.138:41576
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ljtvtu3n
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:41296
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:41296
distributed.worker - INFO -          dashboard at:           10.7.0.136:42964
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2x5709n9
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:41039
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:44888
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:44370
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:44370
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:36111
distributed.worker - INFO -          dashboard at:           10.7.0.140:43453
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:36111
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:41039
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:45639
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.140:33661
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:44888
distributed.worker - INFO -          dashboard at:           10.7.0.132:38622
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.132:36721
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:45639
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-15e350ap
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:41899
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9ij_9pfi
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:41899
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:34757
distributed.worker - INFO -          dashboard at:           10.7.0.140:36913
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          dashboard at:           10.7.0.132:44909
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:34757
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:44161
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:33709
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:36228
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:40289
distributed.worker - INFO -          dashboard at:           10.7.0.140:35445
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:38403
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:40289
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:38403
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:46203
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:46203
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:35028
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:35149
distributed.worker - INFO -          dashboard at:           10.7.0.135:38254
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          dashboard at:           10.7.0.140:45003
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:34421
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:33709
distributed.worker - INFO -          dashboard at:           10.7.0.135:42716
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:33983
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:39083
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:44256
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:35895
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:42301
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:36228
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-y0c6fl0w
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-93uga5ff
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:37583
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:35149
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6braqwc7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_gk6j2p4
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:37582
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:37582
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jeg5qqr_
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:39070
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.140:39190
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wx9ezp_o
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:39638
distributed.worker - INFO -          dashboard at:           10.7.0.140:33394
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:34421
distributed.worker - INFO -          dashboard at:           10.7.0.135:45462
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:44571
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:44571
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:44256
distributed.worker - INFO -          dashboard at:           10.7.0.132:44528
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:34935
distributed.worker - INFO -          dashboard at:           10.7.0.140:41126
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:43376
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:33983
distributed.worker - INFO -          dashboard at:           10.7.0.140:42872
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:44161
distributed.worker - INFO -          dashboard at:           10.7.0.135:36014
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:35028
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-js2m26mq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.132:38400
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:45974
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:45974
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:39083
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xp12xgq6
distributed.worker - INFO -          dashboard at:           10.7.0.135:41297
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:40020
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:40020
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:37583
distributed.worker - INFO -          dashboard at:           10.7.0.132:36334
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          dashboard at:           10.7.0.132:40818
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:34935
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:35895
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:42385
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:42301
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-m7evnpdv
distributed.worker - INFO -          dashboard at:           10.7.0.132:43939
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.132:40159
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gr88a5bx
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-92e99y_u
distributed.worker - INFO -          dashboard at:           10.7.0.140:36830
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:43376
distributed.worker - INFO -          dashboard at:           10.7.0.132:37771
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.140:33565
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z9lu9k0h
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:39638
distributed.worker - INFO -          dashboard at:           10.7.0.132:40405
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-skc1wwcd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nfqfigz0
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-uktoze7x
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fuyhnuzc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:38249
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:35850
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:39288
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:39288
distributed.worker - INFO -          dashboard at:           10.7.0.132:41360
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.135:41579
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vbzh1e6k
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:46429
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:35850
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-beiajgl0
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a_g7sc5a
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-phf7dqbu
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:34652
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:42960
distributed.worker - INFO -          dashboard at:           10.7.0.140:39026
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:38530
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:38530
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l6wpe945
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:33771
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:33771
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:34652
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:46429
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.140:32787
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          dashboard at:           10.7.0.140:33058
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:40533
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:45706
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:45706
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.140:36411
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:33263
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:33263
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6kzwdyx_
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:40313
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:40313
distributed.worker - INFO -          dashboard at:           10.7.0.135:38708
distributed.worker - INFO -          dashboard at:           10.7.0.135:35510
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:42960
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:41456
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:36757
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:36757
distributed.worker - INFO -          dashboard at:           10.7.0.132:37876
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ct51yfc2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:38249
distributed.worker - INFO -          dashboard at:           10.7.0.140:46074
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ww99erfq
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:36620
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:36620
distributed.worker - INFO -          dashboard at:           10.7.0.132:35578
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:36128
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l6o2kfav
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9i5sh3_s
distributed.worker - INFO -          dashboard at:           10.7.0.135:40788
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:38527
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:38527
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:39070
distributed.worker - INFO -          dashboard at:           10.7.0.135:44609
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          dashboard at:           10.7.0.140:39253
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:40305
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:40305
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xyzce67h
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-17eravb3
distributed.worker - INFO -          dashboard at:           10.7.0.132:43447
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          dashboard at:           10.7.0.135:37364
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:42385
distributed.worker - INFO -          dashboard at:           10.7.0.135:46800
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:42863
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.132:36965
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:41456
distributed.worker - INFO -          dashboard at:           10.7.0.140:36573
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bi3ihl09
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:41637
distributed.worker - INFO -          dashboard at:           10.7.0.140:37026
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:34995
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8e2nrvbx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ah2wendk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sxz42mni
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2io750t5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:42863
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hudzl8e0
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4ebobz6c
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:44159
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:37467
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:40533
distributed.worker - INFO -          dashboard at:           10.7.0.135:33806
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:45345
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:45578
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:39241
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:39241
distributed.worker - INFO -          dashboard at:           10.7.0.140:44724
distributed.worker - INFO -          dashboard at:           10.7.0.140:42094
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:36128
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:40233
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:40233
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-npi_e5gp
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:36023
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d0wy8mqq
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:35817
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:45345
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w2emm6ys
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-v4i0om5d
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8vwjtk7c
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:45578
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.132:36862
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:36023
distributed.worker - INFO -          dashboard at:           10.7.0.132:41596
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:40526
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-830vvxzk
distributed.worker - INFO -          dashboard at:           10.7.0.140:33225
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vwamq1g_
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:42312
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:35817
distributed.worker - INFO -          dashboard at:           10.7.0.132:38683
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-m9lh4h2m
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:44159
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-i1v47lm5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:40526
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-caz9gmnb
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          dashboard at:           10.7.0.139:40793
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:36200
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:36200
distributed.worker - INFO -          dashboard at:           10.7.0.135:39831
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:39761
distributed.worker - INFO -          dashboard at:           10.7.0.132:45974
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:39186
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:39186
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p1wrv4nl
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:34995
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b522ppqj
distributed.worker - INFO -          dashboard at:           10.7.0.140:32894
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:46655
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-dsqmkf3p
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:35299
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-du_gkr3l
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-spyx7xsd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:41364
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:41364
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          dashboard at:           10.7.0.135:40238
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7c62bbzg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.139:33398
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:46655
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.140:36789
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:34043
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:43336
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:43336
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.132:34734
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-f1tycfeb
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:42312
distributed.worker - INFO -          dashboard at:           10.7.0.139:40363
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-r8jyki8o
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-k09wzf6h
distributed.worker - INFO -          dashboard at:           10.7.0.135:45354
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b93j9mr6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:39203
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:39203
distributed.worker - INFO -          dashboard at:           10.7.0.132:39048
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:42360
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-78s0abl9
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-cs6vngf5
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:37467
distributed.worker - INFO -          dashboard at:           10.7.0.139:35502
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:38378
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d736tvdn
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:38378
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:34730
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.135:36427
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2df3g7tt
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:34043
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:42360
distributed.worker - INFO -          dashboard at:           10.7.0.135:44637
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z_gaf0ax
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:39761
distributed.worker - INFO -          dashboard at:           10.7.0.139:37555
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:40891
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          dashboard at:           10.7.0.135:43198
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o_dp94i2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.135:35553
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lx_xjh4c
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:46085
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-iuu9ubww
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:38415
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:35299
distributed.worker - INFO -          dashboard at:           10.7.0.139:40244
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vob32cz4
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zja1flsp
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:34730
distributed.worker - INFO -          dashboard at:           10.7.0.135:36908
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:39685
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:40891
distributed.worker - INFO -          dashboard at:           10.7.0.139:45620
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6w2zj2gg
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:35126
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:41637
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:45027
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:46085
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9le0ld3p
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qyip4vdw
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:41936
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:41936
distributed.worker - INFO -          dashboard at:           10.7.0.139:44570
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zulbf1wg
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:44934
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o6b3miqe
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:34997
distributed.worker - INFO -          dashboard at:           10.7.0.135:41311
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:38338
distributed.worker - INFO -          dashboard at:           10.7.0.135:44944
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:44934
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:38338
distributed.worker - INFO -          dashboard at:           10.7.0.135:35177
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ypl3qvj5
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:38346
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:39685
distributed.worker - INFO -          dashboard at:           10.7.0.139:40713
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gbvn7_uq
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:35126
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:42562
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-pf7ahcqh
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-z5pfka0k
distributed.worker - INFO -          dashboard at:           10.7.0.139:46248
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0xxevov1
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:45027
distributed.worker - INFO -          dashboard at:           10.7.0.139:42457
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:46811
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6689hmjc
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.135:40173
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:41900
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:41900
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:38415
distributed.worker - INFO -          dashboard at:           10.7.0.139:46494
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:46811
distributed.worker - INFO -          dashboard at:           10.7.0.135:34602
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:41163
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:41163
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qrxhztsl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:38346
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wayg5yfw
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lz1qms20
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9z5d0zyu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:38039
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:38039
distributed.worker - INFO -          dashboard at:           10.7.0.139:36476
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:42562
distributed.worker - INFO -          dashboard at:           10.7.0.139:46578
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.139:36096
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:39539
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:34997
distributed.worker - INFO -          dashboard at:           10.7.0.139:44004
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-63d81i59
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.139:45030
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          dashboard at:           10.7.0.139:36608
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vv9_qkb_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l2a9bxub
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:39539
distributed.worker - INFO -          dashboard at:           10.7.0.139:38261
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9wk0zxmf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xfe7372_
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-j7ss0r8a
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d_l4602d
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6dc_13x4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-054o3t3j
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:39405
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:39405
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.139:35743
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t_phbqs_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:41807
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:35954
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:41807
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:35954
distributed.worker - INFO -          dashboard at:           10.7.0.139:35606
distributed.worker - INFO -          dashboard at:           10.7.0.139:41180
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-e48m2_0h
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:35162
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-263ztm2e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:35162
distributed.worker - INFO -          dashboard at:           10.7.0.139:46776
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:41206
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:41206
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a0tsantx
distributed.worker - INFO -          dashboard at:           10.7.0.139:39487
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hw1koo05
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:41816
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:41816
distributed.worker - INFO -          dashboard at:           10.7.0.138:37858
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-bz36a9sg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:40583
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:40583
distributed.worker - INFO -          dashboard at:           10.7.0.139:33794
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-57bqdqqu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:39514
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:39514
distributed.worker - INFO -          dashboard at:           10.7.0.136:43924
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0z87k5hf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:44516
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:44516
distributed.worker - INFO -          dashboard at:           10.7.0.133:39696
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-v5k6pzzy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:46848
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:46848
distributed.worker - INFO -          dashboard at:           10.7.0.132:45182
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b2nrqfda
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:34362
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:34362
distributed.worker - INFO -          dashboard at:           10.7.0.132:46626
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:34282
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tgqhvesu
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:34282
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.140:34592
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5sdiiq79
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:36579
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:36579
distributed.worker - INFO -          dashboard at:           10.7.0.135:37325
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0w89irm8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:43789
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:43789
distributed.worker - INFO -          dashboard at:           10.7.0.136:35673
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4wb9hbbr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:41167
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:41167
distributed.worker - INFO -          dashboard at:           10.7.0.140:39109
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-uivgqnpm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:32953
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:32953
distributed.worker - INFO -          dashboard at:           10.7.0.135:34670
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:37672
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-fwek6zqi
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:37672
distributed.worker - INFO -          dashboard at:           10.7.0.133:44804
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-akzyknq8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:46574
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:46574
distributed.worker - INFO -          dashboard at:           10.7.0.136:40884
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9gix6phu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:34754
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:34754
distributed.worker - INFO -          dashboard at:           10.7.0.133:39015
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-n3z1thlt
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:41592
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:41592
distributed.worker - INFO -          dashboard at:           10.7.0.140:41259
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d29te95s
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:39511
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:39511
distributed.worker - INFO -          dashboard at:           10.7.0.135:34536
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9bf7n5nr
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.135:37900
distributed.worker - INFO -          Listening to:     tcp://10.7.0.135:37900
distributed.worker - INFO -          dashboard at:           10.7.0.135:38230
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lvu_i7n0
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:39428
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:39428
distributed.worker - INFO -          dashboard at:           10.7.0.136:36700
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-anhzbh0d
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:45413
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:45413
distributed.worker - INFO -          dashboard at:           10.7.0.136:41336
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-d5uco3c8
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:32832
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:32832
distributed.worker - INFO -          dashboard at:           10.7.0.137:42630
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-alh32cxo
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:32931
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:32931
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:37085
distributed.worker - INFO -          dashboard at:           10.7.0.137:44358
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:43380
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:37085
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wvx9j5wc
distributed.worker - INFO -          dashboard at:           10.7.0.137:39777
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:40743
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:39850
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:43380
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:42991
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:39850
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -          dashboard at:           10.7.0.137:36364
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:42991
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:33337
distributed.worker - INFO -          dashboard at:           10.7.0.137:40306
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-sqlo392o
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:40743
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:33337
distributed.worker - INFO -          dashboard at:           10.7.0.137:45321
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4f8739jz
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -          dashboard at:           10.7.0.137:38132
distributed.worker - INFO -          dashboard at:           10.7.0.137:42110
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-g1gevvnq
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vtoo7djd
distributed.core - INFO - Starting established connection
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-h34p1aj4
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-u2c8n_24
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:33265
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:33265
distributed.worker - INFO -          dashboard at:           10.7.0.137:36315
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:33494
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:36252
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-upo08pls
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:33494
distributed.worker - INFO -          dashboard at:           10.7.0.137:37388
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:36252
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:           10.7.0.137:34056
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4aapi7yf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-yg6tkg0_
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:36835
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:36835
distributed.worker - INFO -          dashboard at:           10.7.0.132:36090
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-whm5geqv
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:39939
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:39939
distributed.worker - INFO -          dashboard at:           10.7.0.132:32880
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9al2ipcs
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:34122
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:34122
distributed.worker - INFO -          dashboard at:           10.7.0.132:40155
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qz6_zp0z
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:35240
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:35240
distributed.worker - INFO -          dashboard at:           10.7.0.132:46130
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5dx0oxik
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:33785
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:33785
distributed.worker - INFO -          dashboard at:           10.7.0.137:36487
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-i8e3f2y2
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:44900
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:44900
distributed.worker - INFO -          dashboard at:           10.7.0.137:36535
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0voxevgz
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:33681
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:33681
distributed.worker - INFO -          dashboard at:           10.7.0.132:43031
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nrvj5_0k
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:39773
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:39773
distributed.worker - INFO -          dashboard at:           10.7.0.140:44795
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mitg67hd
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.132:36054
distributed.worker - INFO -          Listening to:     tcp://10.7.0.132:36054
distributed.worker - INFO -          dashboard at:           10.7.0.132:38106
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kbwuho19
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:42317
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:42317
distributed.worker - INFO -          dashboard at:           10.7.0.140:35614
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.core - INFO - Starting established connection
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wzaz8dky
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:43852
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:43852
distributed.worker - INFO -          dashboard at:           10.7.0.137:40212
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rq392y9n
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:42159
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:42159
distributed.worker - INFO -          dashboard at:           10.7.0.137:36754
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-glzzcvj1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:39036
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:39036
distributed.worker - INFO -          dashboard at:           10.7.0.137:41220
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3w88jimg
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:43571
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:43571
distributed.worker - INFO -          dashboard at:           10.7.0.137:35721
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-37nq0qgl
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:34838
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:34838
distributed.worker - INFO -          dashboard at:           10.7.0.137:42701
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-crkvv6lj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:40476
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:40476
distributed.worker - INFO -          dashboard at:           10.7.0.137:36941
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-jp1wb3cj
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:45950
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:45950
distributed.worker - INFO -          dashboard at:           10.7.0.137:38591
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-adi13_t4
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:34279
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:34279
distributed.worker - INFO -          dashboard at:           10.7.0.138:46269
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ujcef95h
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.136:39822
distributed.worker - INFO -          Listening to:     tcp://10.7.0.136:39822
distributed.worker - INFO -          dashboard at:           10.7.0.136:45618
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8j1ckpjp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:42569
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:42569
distributed.worker - INFO -          dashboard at:           10.7.0.133:34131
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t6rwwpcu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.133:40292
distributed.worker - INFO -          Listening to:     tcp://10.7.0.133:40292
distributed.worker - INFO -          dashboard at:           10.7.0.133:33502
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1o1jxamd
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.140:38434
distributed.worker - INFO -          Listening to:     tcp://10.7.0.140:38434
distributed.worker - INFO -          dashboard at:           10.7.0.140:41910
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b65jo3uq
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:34620
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:39427
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:39427
distributed.worker - INFO -          dashboard at:           10.7.0.137:33705
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:34620
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -          dashboard at:           10.7.0.137:42603
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lsmdwd58
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-dqjqk6fh
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:45918
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:45918
distributed.worker - INFO -          dashboard at:           10.7.0.137:42494
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6hgslpf5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:39675
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:39675
distributed.worker - INFO -          dashboard at:           10.7.0.137:34702
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mdf0gcb7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:35523
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:35523
distributed.worker - INFO -          dashboard at:           10.7.0.137:43237
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-njcen403
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:45759
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:45759
distributed.worker - INFO -          dashboard at:           10.7.0.137:43568
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-f0fptt06
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:37736
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:37736
distributed.worker - INFO -          dashboard at:           10.7.0.137:35966
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3bzgii4_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:40203
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:40203
distributed.worker - INFO -          dashboard at:           10.7.0.139:44708
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7vkx69jf
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:40866
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:40866
distributed.worker - INFO -          dashboard at:           10.7.0.139:40728
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l1pcx6kk
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:43884
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:43884
distributed.worker - INFO -          dashboard at:           10.7.0.137:41167
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-t69j4hcr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:41672
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:41672
distributed.worker - INFO -          dashboard at:           10.7.0.137:41783
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_3e_n1dp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.137:38660
distributed.worker - INFO -          Listening to:     tcp://10.7.0.137:38660
distributed.worker - INFO -          dashboard at:           10.7.0.137:37146
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0k5u3x1e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:34269
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:34269
distributed.worker - INFO -          dashboard at:           10.7.0.139:39035
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qem0xd4w
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:36913
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:36913
distributed.worker - INFO -          dashboard at:           10.7.0.139:42711
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1cde5t61
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.139:39672
distributed.worker - INFO -          Listening to:     tcp://10.7.0.139:39672
distributed.worker - INFO -          dashboard at:           10.7.0.139:46333
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-x1eetewu
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:36952
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:36952
distributed.worker - INFO -          dashboard at:           10.7.0.138:41552
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-96djdbno
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:36994
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:36994
distributed.worker - INFO -          dashboard at:           10.7.0.138:38168
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-chyskfdm
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:39779
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:39779
distributed.worker - INFO -          dashboard at:           10.7.0.138:43921
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o85ouvvv
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:     tcp://10.7.0.138:38437
distributed.worker - INFO -          Listening to:     tcp://10.7.0.138:38437
distributed.worker - INFO -          dashboard at:           10.7.0.138:42686
distributed.worker - INFO - Waiting to connect to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                         40
distributed.worker - INFO -                Memory:                 160.00 GiB
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-46rhvpfr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:      tcp://10.7.0.129:8786
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
Exception in thread Profile:
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 115, in process
    d = state["children"][ident]
KeyError: 'write;/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py;245'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 274, in _watch
    process(frame, None, recent, omit=omit)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 119, in process
    "description": info_frame(frame),
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/profile.py", line 72, in info_frame
    line = linecache.getline(co.co_filename, frame.f_lineno, frame.f_globals).lstrip()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/python-3.10.8-gr23wncdlkfsy2ky42hcmljvrpvextag/lib/python3.10/linecache.py", line 31, in getline
    if 1 <= lineno <= len(lines):
TypeError: '<=' not supported between instances of 'int' and 'NoneType'
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:33681
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:36054
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:33263
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:35817
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:34421
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:36023
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:36620
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:38527
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:35240
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:39288
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:34122
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:37672
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:39083
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:35498
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:40020
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:34926
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:33443
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:43376
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:44159
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:33143
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:35628
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:36835
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:37583
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:44888
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:34754
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:44256
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:40292
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:45345
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:36111
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:35028
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:46655
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:40956
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:36200
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:41196
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:32953
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:37662
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:42380
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:38338
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:45639
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:43953
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:37900
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:45837
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:40289
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:42046
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:42385
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:44563
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:38378
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:36757
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:44516
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:39511
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:35397
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:34205
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:46848
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:39070
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:37411
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:36579
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:43996
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:42360
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:43336
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:34730
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:36528
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:34995
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:33147
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:44571
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:38216
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:41971
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:38888
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:40533
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:41177
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:42569
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:46811
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:37938
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:39428
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:39638
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:40313
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:42647
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:41637
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:38643
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:34043
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:39514
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:40208
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:44161
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:45706
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:41257
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:34935
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:34362
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:46085
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:33503
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:42990
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:33771
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:35109
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:46099
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:32832
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:42958
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:33785
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:33337
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:37582
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:35832
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:33494
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:35292
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:35523
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:36702
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:34620
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:43635
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:32931
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:41296
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:39850
distributed.worker - INFO - Stopping worker at tcp://10.7.0.133:43504
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:44934
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:39163
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:38660
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:39203
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:35865
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:39822
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:39675
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:43789
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:39427
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:40476
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:41672
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:42393
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:44900
distributed.worker - INFO - Stopping worker at tcp://10.7.0.132:39939
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:33582
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:45950
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:46574
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:43884
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:34838
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:42510
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:34818
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:37085
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:36252
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:45413
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:34977
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:42159
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:46203
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:43019
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:34870
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:40489
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:36994
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:38768
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:39186
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:46444
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:36952
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:39571
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:39779
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:43380
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:38620
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:34719
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:38437
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:34697
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:39036
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:41227
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:41171
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:34279
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:42249
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:35299
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:43852
distributed.worker - INFO - Stopping worker at tcp://10.7.0.135:45974
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:35126
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:37750
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:43571
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:36913
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:41816
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:45759
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:34269
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:40120
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:40743
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:41484
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:39539
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:39063
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:43924
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:35954
distributed.worker - INFO - Stopping worker at tcp://10.7.0.136:45345
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:40507
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:35732
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:38346
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:37736
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:35162
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:36602
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:40233
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:39761
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:37422
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:39672
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:33709
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:39405
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:38039
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:37467
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:39685
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:33265
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:40866
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:39773
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:42991
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:40203
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:35850
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:42562
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:34997
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:36128
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:34652
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:36599
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:38415
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:38403
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:42696
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:45578
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:44862
distributed.worker - INFO - Stopping worker at tcp://10.7.0.137:45918
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:41039
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:33983
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:45027
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:41807
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:35149
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:40891
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:39241
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:40583
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:41899
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:43812
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:38249
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:41456
distributed.worker - INFO - Stopping worker at tcp://10.7.0.138:38957
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:38530
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:41936
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:34282
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:38434
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:42317
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:42312
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:36228
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:40526
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:42960
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:35895
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:40305
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:41167
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:34757
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:41163
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:46429
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:41364
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:44370
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:42301
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:41206
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:42863
distributed.worker - INFO - Stopping worker at tcp://10.7.0.139:41900
distributed.worker - INFO - Stopping worker at tcp://10.7.0.140:41592
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:39036'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:37880'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:34766'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36192'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:42244'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:43257'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:33671'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:42915'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:37048'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:35938'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:40376'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:34296'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:39270'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:44880'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:34935'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:35616'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36684'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:34005'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:34393'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:37535'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:40836'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:33042'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:33030'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36816'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:39245'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:34062'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:34010'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:44523'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36786'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:41494'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:40332'
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42238 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO - Worker closed
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42242 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42250 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42240 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:38427'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:37037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36552'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:42161'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:34358'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:45467'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:33314'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:43520'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:42894'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:40563'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:40210'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:39081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:46579'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:41104'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41279'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:35844'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:46129'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:41577'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:45253'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:44095'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41701'
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:37586'
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:39074'
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42246 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:33254'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:36571'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:36826'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:45451'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:43581'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:39759'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:34255'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:42805'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:37959'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:40527'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:43699'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:41942'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:37552'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38882'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:40016'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:46282'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:33341'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:35022'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:36676'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:41149'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41774'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:41426'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:46065'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:46874'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41514'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:39158'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:35893'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:44049'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:46365'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:40632'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:37210'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:45611'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:42183'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:34953'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:33519'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:38502'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:41317'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:35703'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:33933'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.132:42994'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:38324'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:33607'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:35655'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:40794'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:34120'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38446'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:40595'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:34986'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:41664'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:37536'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:34345'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:32983'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:38273'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:46720'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:33504'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:37739'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:35830'
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38180'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:33127'
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38007'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:34610'
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42252 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:46066'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:43913'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:33653'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:45080'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:39879'
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:36121'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:36062'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42260 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:40526'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:41781'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:32873'
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:38949'
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:39326'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:43804'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:44826'
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42254 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:32896'
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:34009'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:38886'
distributed.nanny - INFO - Worker closed
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.136:48676 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33559'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:36575'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:34100'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:39564'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:39307'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:43479'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:41802'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:45206'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.133:43719'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:38506'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:44856'
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:35760'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:42792'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:43644'
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:38675'
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42248 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.135:46239'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:43010'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:42526'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:39747'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:45891'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:36525'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:42863'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:40315'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:45297'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.136:34280'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:42877'
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.136:48670 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:34100'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:46170'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:38192'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:45234'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:36743'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:46330'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:38097'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:44650'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:39114'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:40464'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:39588'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:41534'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.137:40575'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:44188'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:40986'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:41222'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:44329'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:34456'
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:44103'
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:45520'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:39541'
distributed.nanny - INFO - Worker closed
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42258 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:34189'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:40624'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:33085'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:36603'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:33992'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33302'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:34007'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33617'
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:41604'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:41202'
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33237'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:42624'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:42358'
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.133:42256 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:37251'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:35453'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:35415'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:38687'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:41544'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:34858'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:36093'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:33851'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:41521'
distributed.nanny - INFO - Worker closed
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:46570'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:34612'
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:45680'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:33024'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:39521'
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.136:48672 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:36756'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:33337'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:41573'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:37032'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:33041'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:45037'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:40611'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:36710'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:37219'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:36848'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:37768'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:45471'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:37967'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.138:36435'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:41861'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:41846'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:40169'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:46772'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:39119'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:36000'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:42349'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:38328'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:44485'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:38800'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.139:45958'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:44757'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:43298'
distributed.worker - WARNING - Heartbeat to scheduler failed
Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 205, in read
    frames_nbytes = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/worker.py", line 1235, in heartbeat
    response = await retry_operation(
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 366, in retry_operation
    return await retry(
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:46033'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/utils_comm.py", line 351, in retry
    return await coro()
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 887, in send_recv_from_rpc
    result = await send_recv(comm=comm, op=key, **kwargs)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/core.py", line 664, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 221, in read
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:43328'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:38561'
distributed.nanny - INFO - Worker closed
    convert_stream_closed_error(self, e)
  File "/gpfs/users/fernandezx/spack/opt/spack/linux-centos7-cascadelake/gcc-11.2.0/py-distributed-deisa-tvck22hdjddjrkrb4clzsednvt2igzro/lib/python3.10/site-packages/distributed/comm/tcp.py", line 128, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.7.0.136:48674 remote=tcp://10.7.0.129:8786>: Stream is closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:43469'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:37950'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:35348'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.7.0.140:45291'
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Worker closed
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:34062'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:38882'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:34986'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:46772'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:40527'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:33341'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:36192'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:39588'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:35938'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:37552'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:39036'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:37880'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:37048'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:33933'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:33559'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:35655'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:45520'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:33671'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:42244'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:44880'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:41774'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:41577'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:36684'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:39245'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:37535'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:41494'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:34100'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:42161'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:33519'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:35415'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:37210'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:34953'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:43479'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:41802'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:45891'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:39879'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:46282'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:37037'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:33607'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:36848'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:39114'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:37219'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:36816'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:33254'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:35844'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:38007'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:38328'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:33024'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:41279'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:40526'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:34005'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:34189'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:42894'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:34100'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:42805'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:38687'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:37251'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:39521'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:45958'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:43520'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:33992'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:35348'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:41701'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:46365'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:34009'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:36676'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:38949'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:42792'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:45253'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:36121'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:40632'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:33314'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:39326'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:43804'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:44329'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:46874'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:46066'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:34393'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:42994'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:40836'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:44188'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:33851'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:40332'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:34345'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:41317'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:36743'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:42526'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:36435'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:35703'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:32896'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:33237'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:41544'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:35830'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:42915'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:45206'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:35453'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:39074'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:33302'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:33504'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:37586'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:34858'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:36552'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:46330'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:43913'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:43328'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:41604'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:43644'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:34280'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:41222'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:37967'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:39119'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:33042'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:41514'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:38180'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:38502'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:40210'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:43699'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:36525'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:45471'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:37739'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:40624'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:43469'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:45037'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:34296'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:39747'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:39564'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:36756'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:34010'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:38446'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:46720'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:36062'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:40376'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:40575'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:44523'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:45297'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:45467'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:41573'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:33085'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:45234'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:43257'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:44826'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:41861'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:40563'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:34456'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:42863'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:40016'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:46065'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:39759'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:34255'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:38427'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:37032'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:46129'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:44485'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:46579'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:34935'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:33653'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:37536'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:38675'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:38561'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:37959'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:46239'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:45080'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:42349'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:42183'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:41664'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:36603'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:36786'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:32983'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:33617'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:34358'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:36826'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:42358'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:41846'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:38506'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:33030'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:43719'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:46170'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:34007'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:44049'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:39270'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:40464'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.132:43581'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:35022'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:40595'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:36093'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:44757'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:41781'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:38273'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:38324'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:39081'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:40794'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:32873'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:40611'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:39307'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:35760'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:39158'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:33337'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:34766'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:44650'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:43010'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:42624'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:41149'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:41942'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:44103'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:34610'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:41521'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:36575'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:38886'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.135:44095'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:33041'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:41104'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:39541'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:40169'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:46570'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:35893'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:44856'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.139:36000'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:37950'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:46033'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:36710'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:41426'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:45611'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:40315'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:41534'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:38097'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:33127'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:41202'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:38800'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.137:34120'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:38192'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:45291'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:36571'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:37768'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:43298'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:34612'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:40986'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.136:45451'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.140:45680'
distributed.dask_worker - INFO - End worker
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.138:42877'
distributed.dask_worker - INFO - End worker
distributed.nanny - INFO - Closing Nanny at 'tcp://10.7.0.133:35616'
distributed.dask_worker - INFO - End worker
